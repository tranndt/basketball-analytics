{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "import pickle\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display_html\n",
    "from typing import Iterable\n",
    "import warnings\n",
    "from sklearn.exceptions import * \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior = pd.read_csv('./data/00-22/all_seasons_cumu_net_total_prior.csv').drop(columns='Unnamed: 0')\n",
    "data_true = pd.read_csv('./data/00-22/all_seasons_gamelog_facts.csv').drop(columns='Unnamed: 0')\n",
    "index = data_prior[data_prior['game_season'] > 10].dropna().sample(10000,random_state=1).index\n",
    "# index = data_prior[data_prior['game_season'] > 10].dropna().index\n",
    "columns = data_prior.columns[data_prior.columns.str.endswith('net')]\n",
    "\n",
    "X = data_prior.loc[index,columns]\n",
    "y = data_true.loc[index,'game_result']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=data_prior.loc[index,'month'],random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_result_net</th>\n",
       "      <th>pts_net</th>\n",
       "      <th>opp_pts_net</th>\n",
       "      <th>fg_net</th>\n",
       "      <th>fga_net</th>\n",
       "      <th>fg_pct_net</th>\n",
       "      <th>fg3_net</th>\n",
       "      <th>fg3a_net</th>\n",
       "      <th>fg3_pct_net</th>\n",
       "      <th>ft_net</th>\n",
       "      <th>...</th>\n",
       "      <th>efg_pct_net</th>\n",
       "      <th>tov_pct_net</th>\n",
       "      <th>orb_pct_net</th>\n",
       "      <th>ft_rate_net</th>\n",
       "      <th>opp_efg_pct_net</th>\n",
       "      <th>opp_tov_pct_net</th>\n",
       "      <th>drb_pct_net</th>\n",
       "      <th>opp_ft_rate_net</th>\n",
       "      <th>net_pts_net</th>\n",
       "      <th>net_rtg_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11285</th>\n",
       "      <td>0.030769</td>\n",
       "      <td>3.661538</td>\n",
       "      <td>1.492308</td>\n",
       "      <td>1.738462</td>\n",
       "      <td>3.307692</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>2.753846</td>\n",
       "      <td>6.169231</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>-2.569231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>-2.349231</td>\n",
       "      <td>-4.401538</td>\n",
       "      <td>-0.040400</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>-0.470769</td>\n",
       "      <td>1.756923</td>\n",
       "      <td>-0.063062</td>\n",
       "      <td>2.169231</td>\n",
       "      <td>2.563077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40130</th>\n",
       "      <td>-0.039216</td>\n",
       "      <td>3.705882</td>\n",
       "      <td>4.921569</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>1.705882</td>\n",
       "      <td>-0.003451</td>\n",
       "      <td>1.745098</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>0.070980</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>3.254902</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>-1.149020</td>\n",
       "      <td>-3.313725</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>-1.215686</td>\n",
       "      <td>-1.354902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42805</th>\n",
       "      <td>-0.112072</td>\n",
       "      <td>-2.234775</td>\n",
       "      <td>2.155315</td>\n",
       "      <td>-0.418018</td>\n",
       "      <td>1.288108</td>\n",
       "      <td>-0.011710</td>\n",
       "      <td>1.046306</td>\n",
       "      <td>1.471171</td>\n",
       "      <td>0.026527</td>\n",
       "      <td>-2.445045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>1.320919</td>\n",
       "      <td>1.519063</td>\n",
       "      <td>-0.035483</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>-0.039874</td>\n",
       "      <td>1.023297</td>\n",
       "      <td>0.020154</td>\n",
       "      <td>-4.390090</td>\n",
       "      <td>-4.592865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>0.479640</td>\n",
       "      <td>6.736269</td>\n",
       "      <td>-5.585701</td>\n",
       "      <td>1.241004</td>\n",
       "      <td>0.996686</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.802083</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>3.504261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015204</td>\n",
       "      <td>-1.881250</td>\n",
       "      <td>4.502036</td>\n",
       "      <td>0.039678</td>\n",
       "      <td>-0.035384</td>\n",
       "      <td>-1.673106</td>\n",
       "      <td>2.087169</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>12.321970</td>\n",
       "      <td>13.546780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54427</th>\n",
       "      <td>0.131670</td>\n",
       "      <td>7.348579</td>\n",
       "      <td>3.966736</td>\n",
       "      <td>1.765766</td>\n",
       "      <td>3.580042</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>2.115038</td>\n",
       "      <td>3.637561</td>\n",
       "      <td>0.054407</td>\n",
       "      <td>1.702010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010295</td>\n",
       "      <td>-2.682536</td>\n",
       "      <td>-5.212405</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.994387</td>\n",
       "      <td>-4.293001</td>\n",
       "      <td>-0.010658</td>\n",
       "      <td>3.381843</td>\n",
       "      <td>3.266528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51460</th>\n",
       "      <td>0.343750</td>\n",
       "      <td>8.812500</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>2.531250</td>\n",
       "      <td>4.312500</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.968750</td>\n",
       "      <td>0.040344</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>-1.668750</td>\n",
       "      <td>7.309375</td>\n",
       "      <td>-0.014156</td>\n",
       "      <td>-0.034562</td>\n",
       "      <td>-2.825000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>-0.023031</td>\n",
       "      <td>12.312500</td>\n",
       "      <td>12.490625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40738</th>\n",
       "      <td>-0.240260</td>\n",
       "      <td>-5.465368</td>\n",
       "      <td>0.138528</td>\n",
       "      <td>-5.071429</td>\n",
       "      <td>-5.792208</td>\n",
       "      <td>-0.031455</td>\n",
       "      <td>3.965368</td>\n",
       "      <td>10.917749</td>\n",
       "      <td>0.029002</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004855</td>\n",
       "      <td>2.368398</td>\n",
       "      <td>-4.180519</td>\n",
       "      <td>0.023253</td>\n",
       "      <td>-0.030019</td>\n",
       "      <td>-0.857792</td>\n",
       "      <td>-3.537662</td>\n",
       "      <td>0.056831</td>\n",
       "      <td>-5.603896</td>\n",
       "      <td>-6.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39254</th>\n",
       "      <td>0.009519</td>\n",
       "      <td>2.409572</td>\n",
       "      <td>3.093337</td>\n",
       "      <td>-0.910894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019380</td>\n",
       "      <td>4.664463</td>\n",
       "      <td>11.771285</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>-0.433104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>-0.190349</td>\n",
       "      <td>6.137758</td>\n",
       "      <td>-0.010226</td>\n",
       "      <td>0.033569</td>\n",
       "      <td>-1.271840</td>\n",
       "      <td>3.124564</td>\n",
       "      <td>-0.032308</td>\n",
       "      <td>-0.683765</td>\n",
       "      <td>-0.836753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34428</th>\n",
       "      <td>-0.172414</td>\n",
       "      <td>-16.051724</td>\n",
       "      <td>-7.982759</td>\n",
       "      <td>-7.672414</td>\n",
       "      <td>-9.965517</td>\n",
       "      <td>-0.037431</td>\n",
       "      <td>-6.068966</td>\n",
       "      <td>-14.448276</td>\n",
       "      <td>-0.036638</td>\n",
       "      <td>5.362069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069259</td>\n",
       "      <td>0.486207</td>\n",
       "      <td>4.305172</td>\n",
       "      <td>0.092483</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>1.375862</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>-8.068966</td>\n",
       "      <td>-8.594828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49562</th>\n",
       "      <td>-0.051560</td>\n",
       "      <td>-2.499322</td>\n",
       "      <td>-0.936002</td>\n",
       "      <td>-0.817277</td>\n",
       "      <td>4.551560</td>\n",
       "      <td>-0.032787</td>\n",
       "      <td>-0.730891</td>\n",
       "      <td>-2.386929</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>-0.133876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040562</td>\n",
       "      <td>-1.880145</td>\n",
       "      <td>6.286590</td>\n",
       "      <td>-0.010340</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>2.330100</td>\n",
       "      <td>-3.276617</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>-1.563320</td>\n",
       "      <td>-1.588625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_result_net    pts_net  opp_pts_net    fg_net   fga_net   \n",
       "11285         0.030769   3.661538     1.492308  1.738462  3.307692  \\\n",
       "40130        -0.039216   3.705882     4.921569  0.529412  1.705882   \n",
       "42805        -0.112072  -2.234775     2.155315 -0.418018  1.288108   \n",
       "12090         0.479640   6.736269    -5.585701  1.241004  0.996686   \n",
       "54427         0.131670   7.348579     3.966736  1.765766  3.580042   \n",
       "...                ...        ...          ...       ...       ...   \n",
       "51460         0.343750   8.812500    -3.500000  2.531250  4.312500   \n",
       "40738        -0.240260  -5.465368     0.138528 -5.071429 -5.792208   \n",
       "39254         0.009519   2.409572     3.093337 -0.910894  1.000000   \n",
       "34428        -0.172414 -16.051724    -7.982759 -7.672414 -9.965517   \n",
       "49562        -0.051560  -2.499322    -0.936002 -0.817277  4.551560   \n",
       "\n",
       "       fg_pct_net   fg3_net   fg3a_net  fg3_pct_net    ft_net  ...   \n",
       "11285    0.004123  2.753846   6.169231     0.019231 -2.569231  ...  \\\n",
       "40130   -0.003451  1.745098   2.352941     0.070980  0.901961  ...   \n",
       "42805   -0.011710  1.046306   1.471171     0.026527 -2.445045  ...   \n",
       "12090    0.010694  0.750000   1.802083     0.015102  3.504261  ...   \n",
       "54427   -0.000622  2.115038   3.637561     0.054407  1.702010  ...   \n",
       "...           ...       ...        ...          ...       ...  ...   \n",
       "51460    0.007094  4.000000   5.968750     0.040344 -0.250000  ...   \n",
       "40738   -0.031455  3.965368  10.917749     0.029002  0.712121  ...   \n",
       "39254   -0.019380  4.664463  11.771285     0.019032 -0.433104  ...   \n",
       "34428   -0.037431 -6.068966 -14.448276    -0.036638  5.362069  ...   \n",
       "49562   -0.032787 -0.730891  -2.386929     0.005976 -0.133876  ...   \n",
       "\n",
       "       efg_pct_net  tov_pct_net  orb_pct_net  ft_rate_net  opp_efg_pct_net   \n",
       "11285     0.018646    -2.349231    -4.401538    -0.040400         0.011338  \\\n",
       "40130     0.005784    -0.700000     3.254902     0.006000         0.013510   \n",
       "42805    -0.006108     1.320919     1.519063    -0.035483         0.012416   \n",
       "12090     0.015204    -1.881250     4.502036     0.039678        -0.035384   \n",
       "54427     0.010295    -2.682536    -5.212405     0.012788         0.013784   \n",
       "...            ...          ...          ...          ...              ...   \n",
       "51460     0.026250    -1.668750     7.309375    -0.014156        -0.034562   \n",
       "40738    -0.004855     2.368398    -4.180519     0.023253        -0.030019   \n",
       "39254     0.009855    -0.190349     6.137758    -0.010226         0.033569   \n",
       "34428    -0.069259     0.486207     4.305172     0.092483         0.012155   \n",
       "49562    -0.040562    -1.880145     6.286590    -0.010340         0.001767   \n",
       "\n",
       "       opp_tov_pct_net  drb_pct_net  opp_ft_rate_net  net_pts_net  net_rtg_net  \n",
       "11285        -0.470769     1.756923        -0.063062     2.169231     2.563077  \n",
       "40130        -1.149020    -3.313725         0.022000    -1.215686    -1.354902  \n",
       "42805        -0.039874     1.023297         0.020154    -4.390090    -4.592865  \n",
       "12090        -1.673106     2.087169        -0.002315    12.321970    13.546780  \n",
       "54427         0.994387    -4.293001        -0.010658     3.381843     3.266528  \n",
       "...                ...          ...              ...          ...          ...  \n",
       "51460        -2.825000     0.968750        -0.023031    12.312500    12.490625  \n",
       "40738        -0.857792    -3.537662         0.056831    -5.603896    -6.050000  \n",
       "39254        -1.271840     3.124564        -0.032308    -0.683765    -0.836753  \n",
       "34428         1.375862     0.700000         0.046845    -8.068966    -8.594828  \n",
       "49562         2.330100    -3.276617         0.022272    -1.563320    -1.588625  \n",
       "\n",
       "[10000 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11285    1\n",
       "40130    0\n",
       "42805    0\n",
       "12090    1\n",
       "54427    1\n",
       "        ..\n",
       "51460    0\n",
       "40738    0\n",
       "39254    0\n",
       "34428    0\n",
       "49562    1\n",
       "Name: game_result, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 100%|██████████| 4/4 [00:05<00:00,  1.38s/it]    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00     628\n",
       "0.25     146\n",
       "0.50     113\n",
       "0.75     170\n",
       "1.00    1443\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aslist = lambda x: x if isinstance(x,Iterable) and not isinstance(x,str) else [x]\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,models=None) -> None:\n",
    "        self.models = models if models is not None else [RandomForestClassifier(),RidgeClassifier(),SVC(),LogisticRegression()]\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        models = tqdm(self.models)\n",
    "        for model in models:\n",
    "            models.set_description(desc=f\"{model.__class__.__name__}\")\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "\n",
    "    def predict(self,X):\n",
    "        self.predictions = []\n",
    "        for model in self.models:\n",
    "            self.predictions.append(model.predict(X))\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        return self.predictions \n",
    "    \n",
    "    def score(self,X,y,scorers=f1_score,*args):\n",
    "        self.scores = {}\n",
    "        self.predict(X)\n",
    "        for i,scorer in enumerate(aslist(scorers)):\n",
    "            if scorer.__name__ not in self.scores.keys():\n",
    "                self.scores[scorer.__name__] = []\n",
    "            if len(args) == len(aslist(scorers)):\n",
    "                kwargs = args[i]\n",
    "            else:\n",
    "                kwargs = {}\n",
    "            for y_pred in self.predictions:\n",
    "                self.scores[scorer.__name__].append(scorer(y,y_pred,**kwargs))\n",
    "        return self.scores\n",
    "\n",
    "    def accuracy_score(self,y_true,y_preds,axis=0):\n",
    "        y_correct = y_preds == np.tile(y_true,(y_preds.shape[0],1))\n",
    "        return y_correct.mean(axis)\n",
    "    \n",
    "    def mae_score(self,y_true,y_preds,axis=0):\n",
    "        y_error = y_preds - np.tile(y_true,(y_preds.shape[0],1))\n",
    "        return np.abs(y_error).mean(axis)\n",
    "    \n",
    "trainer = Trainer(\n",
    "    models = [RandomForestClassifier(),\n",
    "              RidgeClassifier(),\n",
    "              SVC(),\n",
    "              LogisticRegression()]\n",
    ")\n",
    "trainer.fit(X_train,y_train).score(X_test,y_test,[f1_score])\n",
    "# classification_acc = trainer.accuracy_score(y_test,trainer.predictions,axis=0)\n",
    "# pd.value_counts(classification_acc).sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect Outlier Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierDectection(Trainer):\n",
    "    def __init__(self, models, classification_model = Trainer(), threshold=0.5, kfold = KFold(n_splits=3), is_classification = True) -> None:\n",
    "        super().__init__(models)\n",
    "        self.threshold = threshold\n",
    "        self.kfold = kfold\n",
    "        self.classification_model = classification_model\n",
    "        self.is_classification = is_classification\n",
    "\n",
    "    def detect_outliers(self, X, y):\n",
    "        self.model_predictions = None\n",
    "        for train_index, val_index in self.kfold.split(X):\n",
    "            X_train, y_train = np.array(X)[train_index], np.array(y)[train_index]\n",
    "            X_val, y_val = np.array(X)[val_index], np.array(y)[val_index]\n",
    "            super().fit(X_train, y_train)\n",
    "            if self.model_predictions is None:\n",
    "                self.model_predictions = super().predict(X_val)\n",
    "            else:\n",
    "                self.model_predictions = np.concatenate([self.model_predictions,super().predict(X_val)],axis=1)\n",
    "        if self.is_classification:\n",
    "            self.predictions_accuracy = self.accuracy_score(y,self.model_predictions)\n",
    "            self.outliers = (self.predictions_accuracy < self.threshold).astype(int)\n",
    "        else:\n",
    "            self.predictions_error = self.mae_score(y,self.model_predictions)\n",
    "            self.outliers = (self.predictions_error > self.threshold).astype(int)\n",
    "        return self.outliers\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.detect_outliers(X,y)\n",
    "        self.classification_model.fit(X,self.outliers)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.classification_model.predict(X)\n",
    "        self.predictions = (self.classification_model.predictions.mean(0) > 0).astype(int)\n",
    "        return self.predictions\n",
    "\n",
    "outlier = OutlierDectection(\n",
    "    models = [RandomForestClassifier(),\n",
    "              RidgeClassifier(),\n",
    "              SVC(),\n",
    "              LogisticRegression()],\n",
    "    threshold = 1,\n",
    "    is_classification = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 100%|██████████| 4/4 [00:03<00:00,  1.26it/s]    \n",
      "LogisticRegression: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]    \n",
      "LogisticRegression: 100%|██████████| 4/4 [00:03<00:00,  1.32it/s]    \n",
      "LogisticRegression: 100%|██████████| 4/4 [00:05<00:00,  1.33s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4222\n",
      "1    3278\n",
      "Name: count, dtype: int64\n",
      "0    1164\n",
      "1    1336\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "outlier.fit(X_train,y_train).predict(X_test)\n",
    "print(pd.value_counts(outlier.outliers).sort_index())\n",
    "print(pd.value_counts(outlier.predictions).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 100%|██████████| 4/4 [00:05<00:00,  1.30s/it]    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': [0.6592, 0.6696, 0.6608, 0.6716]}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    models = [RandomForestClassifier(),\n",
    "              RidgeClassifier(),\n",
    "              SVC(),\n",
    "              LogisticRegression()]\n",
    ")\n",
    "\n",
    "trainer.fit(X_train,y_train).score(X_test,y_test,[accuracy_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': [0.5988023952095808,\n",
       "  0.6100299401197605,\n",
       "  0.5950598802395209,\n",
       "  0.6137724550898204]}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.score(X_test[outlier.predictions == 1],y_test[outlier.predictions == 1],[accuracy_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_score': [0.7285223367697594,\n",
       "  0.7379725085910653,\n",
       "  0.7362542955326461,\n",
       "  0.7379725085910653]}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.score(X_test[outlier.predictions == 0],y_test[outlier.predictions == 0],[accuracy_score])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior = pd.read_csv('./data/00-22/all_seasons_cumu_net_total_prior.csv').drop(columns='Unnamed: 0')\n",
    "data_true = pd.read_csv('./data/00-22/all_seasons_gamelog_facts.csv').drop(columns='Unnamed: 0')\n",
    "index = data_prior[data_prior['game_season'] > 10].dropna().sample(10000,random_state=1).index\n",
    "# index = data_prior[data_prior['game_season'] > 10].dropna().index\n",
    "columns = data_prior.columns[data_prior.columns.str.endswith('net')]\n",
    "\n",
    "X = data_prior.loc[index,columns]\n",
    "y = data_true.loc[index,'net_pts']\n",
    "# clamp y between [-20,20]\n",
    "y[y < -20] = -20\n",
    "y[y > 20] = 20\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=data_prior.loc[index,'month'],random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LinearRegression: 100%|██████████| 4/4 [00:15<00:00,  4.00s/it]     \n",
      "LinearRegression: 100%|██████████| 4/4 [00:15<00:00,  3.96s/it]     \n",
      "LinearRegression: 100%|██████████| 4/4 [00:17<00:00,  4.27s/it]     \n",
      "LogisticRegression: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4466\n",
      "1    3034\n",
      "Name: count, dtype: int64\n",
      "0    2187\n",
      "1     313\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "outlier = OutlierDectection(\n",
    "    models = [RandomForestRegressor(),\n",
    "              Ridge(),\n",
    "              SVR(),\n",
    "              LinearRegression()],\n",
    "    threshold = 10,\n",
    "    is_classification=False\n",
    ")\n",
    "\n",
    "outlier.fit(X_train,y_train).predict(X_test)\n",
    "print(pd.value_counts(outlier.outliers).sort_index())\n",
    "print(pd.value_counts(outlier.predictions).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.182197230392264"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(outlier.predictions_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LinearRegression: 100%|██████████| 4/4 [00:25<00:00,  6.34s/it]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r2_score': [0.14453487711927904, 0.18209516002545756, 0.16673027282630548, 0.18420438386721505], 'mean_absolute_error': [8.971092, 8.831923199249784, 8.807930922758306, 8.820108039332474]}\n",
      "{'r2_score': [0.0072010316214873304, 0.10918470047867046, 0.06394246267507697, 0.11431023164433685], 'mean_absolute_error': [9.207987220447286, 8.718308596061618, 8.871092814835796, 8.68175604130981]}\n",
      "{'r2_score': [0.16115972403985268, 0.19050075491027174, 0.17895004910939138, 0.19222555820422016], 'mean_absolute_error': [8.937187928669413, 8.84818354255015, 8.798891292113472, 8.839908759671339]}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    models = [RandomForestRegressor(),\n",
    "              Ridge(),\n",
    "              SVR(),\n",
    "              LinearRegression()]\n",
    ")\n",
    "\n",
    "trainer.fit(X_train,y_train)\n",
    "print(trainer.score(X_test,y_test,[r2_score,mean_absolute_error]))\n",
    "print(trainer.score(X_test[outlier.predictions == 1],y_test[outlier.predictions == 1],[r2_score,mean_absolute_error]))  \n",
    "print(trainer.score(X_test[outlier.predictions == 0],y_test[outlier.predictions == 0],[r2_score,mean_absolute_error]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.67745451,  0.31913676,  0.31913676, ...,  1.67745451,\n",
       "       -0.6147067 ,  0.74361105])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_trf = StandardScaler().fit_transform(y_train.values.reshape(-1,1)).flatten()\n",
    "y_test_trf = StandardScaler().fit_transform(y_test.values.reshape(-1,1)).flatten()\n",
    "y_train_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LinearRegression: 100%|██████████| 4/4 [00:14<00:00,  3.74s/it]     \n",
      "LinearRegression: 100%|██████████| 4/4 [00:15<00:00,  3.83s/it]     \n",
      "LinearRegression: 100%|██████████| 4/4 [00:15<00:00,  3.77s/it]     \n",
      "LogisticRegression: 100%|██████████| 4/4 [00:06<00:00,  1.61s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2772\n",
      "1    4728\n",
      "Name: count, dtype: int64\n",
      "1    2500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "outlier = OutlierDectection(\n",
    "    models = [RandomForestRegressor(),\n",
    "              Ridge(),\n",
    "              SVR(),\n",
    "              LinearRegression()],\n",
    "    threshold = 0.5,\n",
    "    is_classification=False\n",
    ")\n",
    "\n",
    "outlier.fit(X_train,y_train_trf).predict(X_test)\n",
    "print(pd.value_counts(outlier.outliers).sort_index())\n",
    "print(pd.value_counts(outlier.predictions).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LinearRegression: 100%|██████████| 4/4 [00:25<00:00,  6.36s/it]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r2_score': [0.15398809874807373, 0.18339591794511367, 0.12352823096493881, 0.18551920925667875], 'mean_absolute_error': [0.7599404288077121, 0.7521651885117197, 0.7697820282330942, 0.7512925815227507]}\n",
      "{'r2_score': [0.15398809874807373, 0.18339591794511367, 0.12352823096493881, 0.18551920925667875], 'mean_absolute_error': [0.7599404288077121, 0.7521651885117197, 0.7697820282330942, 0.7512925815227507]}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    models = [RandomForestRegressor(),\n",
    "              Ridge(),\n",
    "              SVR(),\n",
    "              LinearRegression()]\n",
    ")\n",
    "\n",
    "trainer.fit(X_train,y_train_trf)\n",
    "print(trainer.score(X_test,y_test_trf,[r2_score,mean_absolute_error]))\n",
    "print(trainer.score(X_test[outlier.predictions == 1],y_test_trf[outlier.predictions == 1],[r2_score,mean_absolute_error]))  \n",
    "# print(trainer.score(X_test[outlier.predictions == 0],y_test[outlier.predictions == 0],[r2_score,mean_absolute_error]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.plot.hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
