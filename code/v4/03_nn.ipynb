{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp39-cp39-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from torchvision) (1.24.2)\n",
      "Collecting requests (from torchvision)\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: torch==2.0.0 in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: filelock in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->torchvision)\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-macosx_11_0_arm64.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.0/123.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5 (from requests->torchvision)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1 (from requests->torchvision)\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torchvision)\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jasetran/Jase/UM/Git/basketball-analytics/.venv/lib/python3.9/site-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests, torchvision\n",
      "Successfully installed certifi-2022.12.7 charset-normalizer-3.1.0 idna-3.4 requests-2.28.2 torchvision-0.15.1 urllib3-1.26.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install torch\n",
    "%pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "import pickle\n",
    "import torchvision\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display_html\n",
    "from typing import Iterable\n",
    "import warnings\n",
    "from sklearn.exceptions import * \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prior = pd.read_csv('./data/00-22/all_seasons_cumu_net_total_prior.csv').drop(columns='Unnamed: 0')\n",
    "data_true = pd.read_csv('./data/00-22/all_seasons_gamelog_facts.csv').drop(columns='Unnamed: 0')\n",
    "index = data_prior[data_prior['game_season'] > 10].dropna().sample(10000,random_state=1).index\n",
    "columns = data_prior.columns[data_prior.columns.str.endswith('net')]\n",
    "\n",
    "X = data_prior.loc[index,columns]\n",
    "y = data_true.loc[index,'game_result']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=data_prior.loc[index,'month'],random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class NeuralNetwork(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, learning_rate=0.001, batch_size=32, dropout=0.5, num_epochs=100, scaler = StandardScaler()):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.dropout = dropout\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        ).to(self.device)\n",
    "        self.criterion = nn.BCELoss()  # Binary cross-entropy loss\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.scaler = scaler\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_tensor = torch.tensor(self.scaler.fit_transform(X), dtype=torch.float32).to(self.device)\n",
    "        # X_tensor = torchvision.transforms.Nor\n",
    "        y_tensor = torch.tensor(np.array(y), dtype=torch.float32).to(self.device)\n",
    "        num_samples = X.shape[0]\n",
    "        num_batches = (num_samples + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        epoch_range = tqdm(range(self.num_epochs))\n",
    "        for epoch in epoch_range:\n",
    "            running_loss = 0.0\n",
    "            corr_preds = 0\n",
    "            for batch in range(num_batches):\n",
    "                start_idx = batch * self.batch_size\n",
    "                end_idx = min(start_idx + self.batch_size, num_samples)\n",
    "                batch_X = X_tensor[start_idx:end_idx,:]\n",
    "                batch_y = y_tensor[start_idx:end_idx]\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = self.criterion(outputs.squeeze(), batch_y)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                corr_preds += sum(torch.round(outputs).cpu().squeeze().detach().numpy() == batch_y.numpy())\n",
    "\n",
    "            # Print the loss for this epoch\n",
    "            epoch_range.set_description('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}'.format(epoch+1, self.num_epochs, running_loss/num_batches, corr_preds/len(y_tensor)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_tensor = torch.tensor(self.scaler.fit_transform(X), dtype=torch.float32).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor)\n",
    "            y_pred = torch.round(outputs).cpu().numpy()\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_tensor = torch.tensor(self.scaler.fit_transform(X), dtype=torch.float32).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor)\n",
    "            proba = outputs.cpu().numpy()\n",
    "        return proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [500/500], Train Loss: 0.5064, Train Acc: 0.7552: 100%|██████████| 500/500 [01:31<00:00,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[701 558]\n",
      " [420 821]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(input_dim=X.values.shape[1], hidden_dim=128, output_dim=1, \n",
    "                       learning_rate = 0.001, dropout=0.3, num_epochs=500)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[701 558]\n",
      " [420 821]]\n",
      "0.6088\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7710141 ],\n",
       "       [0.7144489 ],\n",
       "       [0.65372354],\n",
       "       ...,\n",
       "       [0.47556797],\n",
       "       [0.6358679 ],\n",
       "       [0.05204496]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = model.predict_proba(X_test)\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confident_preds = (y_proba > 0.7) | (y_proba <  0.3)\n",
    "print(confusion_matrix(y_test[confident_preds],y_pred[confident_preds]))\n",
    "print(accuracy_score(y_test[confident_preds],y_pred[confident_preds]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90 71]\n",
      " [71 74]]\n",
      "0.5359477124183006\n"
     ]
    }
   ],
   "source": [
    "confident_preds = y_proba.max(1) <= 0.7\n",
    "print(confusion_matrix(y_test[confident_preds],y_pred[confident_preds]))\n",
    "print(accuracy_score(y_test[confident_preds],y_pred[confident_preds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9999622 , 0.9999974 , 0.9978237 , ..., 0.99999714, 0.9999876 ,\n",
       "       1.        ], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_result_net</th>\n",
       "      <th>pts_net</th>\n",
       "      <th>opp_pts_net</th>\n",
       "      <th>fg_net</th>\n",
       "      <th>fga_net</th>\n",
       "      <th>fg_pct_net</th>\n",
       "      <th>fg3_net</th>\n",
       "      <th>fg3a_net</th>\n",
       "      <th>fg3_pct_net</th>\n",
       "      <th>ft_net</th>\n",
       "      <th>...</th>\n",
       "      <th>efg_pct_net</th>\n",
       "      <th>tov_pct_net</th>\n",
       "      <th>orb_pct_net</th>\n",
       "      <th>ft_rate_net</th>\n",
       "      <th>opp_efg_pct_net</th>\n",
       "      <th>opp_tov_pct_net</th>\n",
       "      <th>drb_pct_net</th>\n",
       "      <th>opp_ft_rate_net</th>\n",
       "      <th>net_pts_net</th>\n",
       "      <th>net_rtg_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11285</th>\n",
       "      <td>0.030769</td>\n",
       "      <td>3.661538</td>\n",
       "      <td>1.492308</td>\n",
       "      <td>1.738462</td>\n",
       "      <td>3.307692</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>2.753846</td>\n",
       "      <td>6.169231</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>-2.569231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>-2.349231</td>\n",
       "      <td>-4.401538</td>\n",
       "      <td>-0.040400</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>-0.470769</td>\n",
       "      <td>1.756923</td>\n",
       "      <td>-0.063062</td>\n",
       "      <td>2.169231</td>\n",
       "      <td>2.563077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40130</th>\n",
       "      <td>-0.039216</td>\n",
       "      <td>3.705882</td>\n",
       "      <td>4.921569</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>1.705882</td>\n",
       "      <td>-0.003451</td>\n",
       "      <td>1.745098</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>0.070980</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>3.254902</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>-1.149020</td>\n",
       "      <td>-3.313725</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>-1.215686</td>\n",
       "      <td>-1.354902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42805</th>\n",
       "      <td>-0.112072</td>\n",
       "      <td>-2.234775</td>\n",
       "      <td>2.155315</td>\n",
       "      <td>-0.418018</td>\n",
       "      <td>1.288108</td>\n",
       "      <td>-0.011710</td>\n",
       "      <td>1.046306</td>\n",
       "      <td>1.471171</td>\n",
       "      <td>0.026527</td>\n",
       "      <td>-2.445045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006108</td>\n",
       "      <td>1.320919</td>\n",
       "      <td>1.519063</td>\n",
       "      <td>-0.035483</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>-0.039874</td>\n",
       "      <td>1.023297</td>\n",
       "      <td>0.020154</td>\n",
       "      <td>-4.390090</td>\n",
       "      <td>-4.592865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>0.479640</td>\n",
       "      <td>6.736269</td>\n",
       "      <td>-5.585701</td>\n",
       "      <td>1.241004</td>\n",
       "      <td>0.996686</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.802083</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>3.504261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015204</td>\n",
       "      <td>-1.881250</td>\n",
       "      <td>4.502036</td>\n",
       "      <td>0.039678</td>\n",
       "      <td>-0.035384</td>\n",
       "      <td>-1.673106</td>\n",
       "      <td>2.087169</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>12.321970</td>\n",
       "      <td>13.546780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54427</th>\n",
       "      <td>0.131670</td>\n",
       "      <td>7.348579</td>\n",
       "      <td>3.966736</td>\n",
       "      <td>1.765766</td>\n",
       "      <td>3.580042</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>2.115038</td>\n",
       "      <td>3.637561</td>\n",
       "      <td>0.054407</td>\n",
       "      <td>1.702010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010295</td>\n",
       "      <td>-2.682536</td>\n",
       "      <td>-5.212405</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.994387</td>\n",
       "      <td>-4.293001</td>\n",
       "      <td>-0.010658</td>\n",
       "      <td>3.381843</td>\n",
       "      <td>3.266528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51460</th>\n",
       "      <td>0.343750</td>\n",
       "      <td>8.812500</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>2.531250</td>\n",
       "      <td>4.312500</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.968750</td>\n",
       "      <td>0.040344</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>-1.668750</td>\n",
       "      <td>7.309375</td>\n",
       "      <td>-0.014156</td>\n",
       "      <td>-0.034562</td>\n",
       "      <td>-2.825000</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>-0.023031</td>\n",
       "      <td>12.312500</td>\n",
       "      <td>12.490625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40738</th>\n",
       "      <td>-0.240260</td>\n",
       "      <td>-5.465368</td>\n",
       "      <td>0.138528</td>\n",
       "      <td>-5.071429</td>\n",
       "      <td>-5.792208</td>\n",
       "      <td>-0.031455</td>\n",
       "      <td>3.965368</td>\n",
       "      <td>10.917749</td>\n",
       "      <td>0.029002</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004855</td>\n",
       "      <td>2.368398</td>\n",
       "      <td>-4.180519</td>\n",
       "      <td>0.023253</td>\n",
       "      <td>-0.030019</td>\n",
       "      <td>-0.857792</td>\n",
       "      <td>-3.537662</td>\n",
       "      <td>0.056831</td>\n",
       "      <td>-5.603896</td>\n",
       "      <td>-6.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39254</th>\n",
       "      <td>0.009519</td>\n",
       "      <td>2.409572</td>\n",
       "      <td>3.093337</td>\n",
       "      <td>-0.910894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019380</td>\n",
       "      <td>4.664463</td>\n",
       "      <td>11.771285</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>-0.433104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>-0.190349</td>\n",
       "      <td>6.137758</td>\n",
       "      <td>-0.010226</td>\n",
       "      <td>0.033569</td>\n",
       "      <td>-1.271840</td>\n",
       "      <td>3.124564</td>\n",
       "      <td>-0.032308</td>\n",
       "      <td>-0.683765</td>\n",
       "      <td>-0.836753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34428</th>\n",
       "      <td>-0.172414</td>\n",
       "      <td>-16.051724</td>\n",
       "      <td>-7.982759</td>\n",
       "      <td>-7.672414</td>\n",
       "      <td>-9.965517</td>\n",
       "      <td>-0.037431</td>\n",
       "      <td>-6.068966</td>\n",
       "      <td>-14.448276</td>\n",
       "      <td>-0.036638</td>\n",
       "      <td>5.362069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069259</td>\n",
       "      <td>0.486207</td>\n",
       "      <td>4.305172</td>\n",
       "      <td>0.092483</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>1.375862</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>-8.068966</td>\n",
       "      <td>-8.594828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49562</th>\n",
       "      <td>-0.051560</td>\n",
       "      <td>-2.499322</td>\n",
       "      <td>-0.936002</td>\n",
       "      <td>-0.817277</td>\n",
       "      <td>4.551560</td>\n",
       "      <td>-0.032787</td>\n",
       "      <td>-0.730891</td>\n",
       "      <td>-2.386929</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>-0.133876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040562</td>\n",
       "      <td>-1.880145</td>\n",
       "      <td>6.286590</td>\n",
       "      <td>-0.010340</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>2.330100</td>\n",
       "      <td>-3.276617</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>-1.563320</td>\n",
       "      <td>-1.588625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_result_net    pts_net  opp_pts_net    fg_net   fga_net   \n",
       "11285         0.030769   3.661538     1.492308  1.738462  3.307692  \\\n",
       "40130        -0.039216   3.705882     4.921569  0.529412  1.705882   \n",
       "42805        -0.112072  -2.234775     2.155315 -0.418018  1.288108   \n",
       "12090         0.479640   6.736269    -5.585701  1.241004  0.996686   \n",
       "54427         0.131670   7.348579     3.966736  1.765766  3.580042   \n",
       "...                ...        ...          ...       ...       ...   \n",
       "51460         0.343750   8.812500    -3.500000  2.531250  4.312500   \n",
       "40738        -0.240260  -5.465368     0.138528 -5.071429 -5.792208   \n",
       "39254         0.009519   2.409572     3.093337 -0.910894  1.000000   \n",
       "34428        -0.172414 -16.051724    -7.982759 -7.672414 -9.965517   \n",
       "49562        -0.051560  -2.499322    -0.936002 -0.817277  4.551560   \n",
       "\n",
       "       fg_pct_net   fg3_net   fg3a_net  fg3_pct_net    ft_net  ...   \n",
       "11285    0.004123  2.753846   6.169231     0.019231 -2.569231  ...  \\\n",
       "40130   -0.003451  1.745098   2.352941     0.070980  0.901961  ...   \n",
       "42805   -0.011710  1.046306   1.471171     0.026527 -2.445045  ...   \n",
       "12090    0.010694  0.750000   1.802083     0.015102  3.504261  ...   \n",
       "54427   -0.000622  2.115038   3.637561     0.054407  1.702010  ...   \n",
       "...           ...       ...        ...          ...       ...  ...   \n",
       "51460    0.007094  4.000000   5.968750     0.040344 -0.250000  ...   \n",
       "40738   -0.031455  3.965368  10.917749     0.029002  0.712121  ...   \n",
       "39254   -0.019380  4.664463  11.771285     0.019032 -0.433104  ...   \n",
       "34428   -0.037431 -6.068966 -14.448276    -0.036638  5.362069  ...   \n",
       "49562   -0.032787 -0.730891  -2.386929     0.005976 -0.133876  ...   \n",
       "\n",
       "       efg_pct_net  tov_pct_net  orb_pct_net  ft_rate_net  opp_efg_pct_net   \n",
       "11285     0.018646    -2.349231    -4.401538    -0.040400         0.011338  \\\n",
       "40130     0.005784    -0.700000     3.254902     0.006000         0.013510   \n",
       "42805    -0.006108     1.320919     1.519063    -0.035483         0.012416   \n",
       "12090     0.015204    -1.881250     4.502036     0.039678        -0.035384   \n",
       "54427     0.010295    -2.682536    -5.212405     0.012788         0.013784   \n",
       "...            ...          ...          ...          ...              ...   \n",
       "51460     0.026250    -1.668750     7.309375    -0.014156        -0.034562   \n",
       "40738    -0.004855     2.368398    -4.180519     0.023253        -0.030019   \n",
       "39254     0.009855    -0.190349     6.137758    -0.010226         0.033569   \n",
       "34428    -0.069259     0.486207     4.305172     0.092483         0.012155   \n",
       "49562    -0.040562    -1.880145     6.286590    -0.010340         0.001767   \n",
       "\n",
       "       opp_tov_pct_net  drb_pct_net  opp_ft_rate_net  net_pts_net  net_rtg_net  \n",
       "11285        -0.470769     1.756923        -0.063062     2.169231     2.563077  \n",
       "40130        -1.149020    -3.313725         0.022000    -1.215686    -1.354902  \n",
       "42805        -0.039874     1.023297         0.020154    -4.390090    -4.592865  \n",
       "12090        -1.673106     2.087169        -0.002315    12.321970    13.546780  \n",
       "54427         0.994387    -4.293001        -0.010658     3.381843     3.266528  \n",
       "...                ...          ...              ...          ...          ...  \n",
       "51460        -2.825000     0.968750        -0.023031    12.312500    12.490625  \n",
       "40738        -0.857792    -3.537662         0.056831    -5.603896    -6.050000  \n",
       "39254        -1.271840     3.124564        -0.032308    -0.683765    -0.836753  \n",
       "34428         1.375862     0.700000         0.046845    -8.068966    -8.594828  \n",
       "49562         2.330100    -3.276617         0.022272    -1.563320    -1.588625  \n",
       "\n",
       "[10000 rows x 55 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
