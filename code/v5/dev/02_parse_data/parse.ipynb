{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'../../')\n",
    "from scripts.base import *\n",
    "import scripts.base as base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import bs4\n",
    "from IPython.display import display_html,clear_output\n",
    "import re\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import itertools\n",
    "from tqdm import tqdm,trange\n",
    "\n",
    "dtype_backend = 'pyarrow'\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('compute.use_numexpr', False)\n",
    "# pd.set_option('compute.default_to_pandas', False)\n",
    "pd.set_option('io.parquet.engine', 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_tables(tables,sleep=2):\n",
    "    if isinstance(tables,dict):\n",
    "        tables_list = tables.items()\n",
    "    elif isinstance(tables,(list,tuple)):\n",
    "        tables_list = enumerate(tables)\n",
    "    tables_list = tqdm(tables_list)\n",
    "    for table_id, table in tables_list:\n",
    "        tables_list.set_description(table_id)\n",
    "        display_html(table)\n",
    "        time.sleep(sleep)\n",
    "        clear_output()\n",
    "\n",
    "def convert_time_to_minutes(time_str):\n",
    "    if pd.notnull(time_str):\n",
    "        minutes, seconds = time_str.split(':')\n",
    "        return float(minutes) + float(seconds) / 60.0\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "def convert_series_dtype(series):\n",
    "    # backend = {'numpy':np, 'pyarrow':pa}[backend]\n",
    "    try:    return series.astype(pd.Int32Dtype())\n",
    "    except: pass\n",
    "    try:    return series.astype(pd.Float32Dtype())\n",
    "    except: pass\n",
    "    try:    return series.astype(str).apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "    except: pass\n",
    "    try:\n",
    "        if series.str.contains('\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}').all():\n",
    "            return series.apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "        elif series.str.contains('\\d{4}-\\d{2}-\\d{2}').all():\n",
    "            return pd.to_datetime(series, format='%Y-%m-%d')\n",
    "        elif series.str.isnumeric().all():\n",
    "            return series.astype(pd.Int32Dtype())\n",
    "        elif series.str.isnumeric().any():\n",
    "            return series.astype(pd.Float32Dtype())\n",
    "    except: pass\n",
    "    return series \n",
    "\n",
    "def parse_html_table(html_text,**kwargs):\n",
    "    return pd.concat(pd.read_html(html_text,flavor='bs4',dtype_backend=dtype_backend,**kwargs))\n",
    "\n",
    "def parse_html_table_as_hrefs(html_text,columns=None):\n",
    "    df_hrefs = parse_html_table(html_text,extract_links='all')\n",
    "    df_hrefs = df_hrefs.apply(lambda x: x.apply(lambda y: ast.literal_eval(y)[1]))\n",
    "    if columns is not None:\n",
    "        df_hrefs.columns = columns\n",
    "    return df_hrefs\n",
    "\n",
    "def __parse_boxscores_tables_type1__(html_text):\n",
    "    # parse line score and four factors\n",
    "    html_soup = make_soup(html_text)\n",
    "    parsed_boxscores_tables = {}\n",
    "    for table_elmt in html_soup.find_all('table'):\n",
    "        table_id = table_elmt.get('id')\n",
    "        if table_id in ['line_score','four_factors']:\n",
    "            df = parse_html_table(str(table_elmt)).droplevel(0,axis=1)\n",
    "            df.columns = df.columns.str.lower()\n",
    "            df.rename(columns={'unnamed: 0_level_1':'team'},inplace=True)\n",
    "            df_hrefs = parse_html_table_as_hrefs(str(table_elmt),columns=df.columns)\n",
    "            df.insert(1,'team_href',df_hrefs['team'])\n",
    "            parsed_boxscores_tables[table_id] = df\n",
    "    return parsed_boxscores_tables\n",
    "            \n",
    "def __parse_boxscores_tables_type2__(html_text):\n",
    "    # parse box scores that starts with box\n",
    "    table_away_home_teams = __parse_game_info_tables__(html_text)['info-away-home-teams']\n",
    "    away,home = table_away_home_teams['team_id']\n",
    "    away_href,home_href = table_away_home_teams['team_href']\n",
    "\n",
    "    html_soup = make_soup(html_text)\n",
    "    parsed_boxscores_tables = {}\n",
    "    for table_elmt in html_soup.find_all('table'):\n",
    "        table_id = table_elmt.get('id')\n",
    "        if table_id and table_id.startswith('box'):\n",
    "            if away in table_id:\n",
    "                table_id = re.sub(away,'away',table_id)\n",
    "                team = away\n",
    "                team_href = away_href\n",
    "            elif home in table_id:\n",
    "                table_id = re.sub(home,'home',table_id)\n",
    "                team = home\n",
    "                team_href = home_href\n",
    "\n",
    "            df_players = parse_html_table(str(table_elmt)).droplevel(0,axis=1)\n",
    "            df_players.columns = df_players.columns.str.lower()\n",
    "            df_players.rename(columns={'starters':'player'},inplace=True)\n",
    "            df_hrefs = parse_html_table_as_hrefs(str(table_elmt),columns=df_players.columns)\n",
    "            df_players = df_players.replace('Did Not Play', float('nan'))\n",
    "            df_players.insert(1,'player_href', df_hrefs['player'])\n",
    "            df_players.insert(2, 'played', df_players['mp'].notna().astype(int))\n",
    "\n",
    "            df_total = df_players[df_players['player'].str.startswith('Team Totals')].apply(convert_series_dtype)\n",
    "            df_total.insert(0,'team',df_total.pop('player'))\n",
    "            df_total.insert(1,'team_href',df_total.pop('player_href'))\n",
    "\n",
    "            df_players = df_players[~df_players['player'].isin(('Reserves','Team Totals'))].apply(convert_series_dtype)\n",
    "            df_players.insert(0,'team',team)\n",
    "            df_players.insert(1,'team_href',team_href)\n",
    "\n",
    "            parsed_boxscores_tables[table_id] = df_players\n",
    "            parsed_boxscores_tables[table_id+'-total'] = df_total\n",
    "    return parsed_boxscores_tables\n",
    "\n",
    "def __parse_game_info_tables__(html_text):\n",
    "    html_soup = make_soup(html_text)\n",
    "    away,home = html_soup.select('div .scorebox strong a')\n",
    "    df_game_info = []\n",
    "    for team_type, team_element in zip(('away','home'),(away,home)):\n",
    "        team_name = team_element.text\n",
    "        team_href = team_element['href']\n",
    "        team_id,season = re.search(r'/teams/(?P<team>\\w+)/(?P<season>\\d+)\\.html',team_href).groups()\n",
    "        df_game_info.append([team_id, team_href, team_name, season, team_type])\n",
    "    df_game_info = pd.DataFrame(df_game_info,columns = ['team_id', 'team_href', 'team_name', 'season', 'team_type'])\n",
    "    return {'info-away-home-teams': df_game_info}    \n",
    "    \n",
    "def parse_all_boxscores_tables(html_text):\n",
    "    parsed_boxscores_tables = {\n",
    "        **__parse_game_info_tables__(html_text),\n",
    "        **__parse_boxscores_tables_type1__(html_text),\n",
    "        **__parse_boxscores_tables_type2__(html_text),\n",
    "    }\n",
    "    return parsed_boxscores_tables\n",
    "\n",
    "href = 'https:/www.basketball-reference.com/boxscores/202301100GSW.html'\n",
    "url = f'{href}'\n",
    "html_text = fetch_html(url,source=base.LOCAL_HOST)\n",
    "parsed_boxscores_tables = parse_all_boxscores_tables(html_text)\n",
    "\n",
    "# iter_tables(parsed_boxscores_tables,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    # pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "def __parse_pbp_tables_type1__(html_text):\n",
    "    html_soup = make_soup(html_text)\n",
    "    pbp_table_elmt = html_soup.find('table',{'id':'pbp'})\n",
    "    player_href_table = pd.DataFrame({(a.text,a['href']) for a in pbp_table_elmt.find_all('a')},columns=['player','player_href'])\n",
    "    return {'player-href': player_href_table}\n",
    "\n",
    "def __parse_pbp_tables_type2__(html_text):\n",
    "    html_soup = make_soup(html_text)\n",
    "    pbp_table_elmt = html_soup.find('table',{'id':'pbp'})\n",
    "\n",
    "    pbp_table = pd.concat(pd.read_html(str(pbp_table_elmt),flavor='bs4',dtype_backend=dtype_backend))\n",
    "    pbp_table.columns = pbp_table.columns.droplevel(0)\n",
    "    away,home = pbp_table.columns[[1,5]]\n",
    "    pbp_table = pbp_table.rename({away:'away_action',home:'home_action','Unnamed: 2_level_1':'away_pts_change','Unnamed: 4_level_1':'home_pts_change'},axis=1)\n",
    "    pbp_table.insert(1,'away',away)\n",
    "    pbp_table.insert(len(pbp_table.columns),'home',home)\n",
    "    pbp_table.columns = pbp_table.columns.str.lower()\n",
    "\n",
    "    time_series = pbp_table[pbp_table['time'].str.contains('Q') | pbp_table['time'].str.contains('OT')]['time']\n",
    "    quarter_marks = [0] + list(time_series.index) + [None]\n",
    "    quarter_order = range(1,16) # maximum expected Qs = 15 (OT1 = 5, OT2 = 6,...)\n",
    "    for q,(i,j) in list(zip(quarter_order,pairwise(quarter_marks))):\n",
    "        pbp_table.loc[pbp_table.index[i:j],'quarter'] = q\n",
    "    pbp_table.insert(0,'quarter',pbp_table.pop('quarter'))\n",
    "    # pbp_table.insert(2,'time_min',pbp_table['time'].apply(lambda x: int(x.split(':')[0]) if pd.notnull(x) and ':' in x else pd.NA))\n",
    "    # pbp_table.insert(3,'time_sec',pbp_table['time'].apply(lambda x: float(x.split(':')[1]) if pd.notnull(x) and ':' in x else pd.NA))\n",
    "    pbp_table = pbp_table[pbp_table['time'].str.contains(':')].reset_index(drop=True)\n",
    "    return {'pbp': pbp_table}\n",
    "\n",
    "\n",
    "def parse_all_pbp_tables(html_text):\n",
    "    parsed_pbp_tables = {\n",
    "        **__parse_game_info_tables__(html_text),\n",
    "        **__parse_pbp_tables_type1__(html_text),\n",
    "        **__parse_pbp_tables_type2__(html_text),\n",
    "    }\n",
    "    return parsed_pbp_tables\n",
    "\n",
    "href = 'https:/www.basketball-reference.com/boxscores/pbp/202211090OKC.html'\n",
    "url = f'{href}'\n",
    "html_text = fetch_html(url,source=base.LOCAL_HOST)\n",
    "parsed_pbp_tables = parse_all_pbp_tables(html_text)\n",
    "\n",
    "# iter_tables(parsed_pbp_tables,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __parse_shotchart_tables_type1__(html_text):\n",
    "    html_soup = make_soup(html_text)\n",
    "    table_away_home_teams = __parse_game_info_tables__(html_text)['info-away-home-teams']\n",
    "    away,home = table_away_home_teams['team_id']\n",
    "    away_href,home_href = table_away_home_teams['team_href']\n",
    "\n",
    "    parsed_shot_charts = {}\n",
    "    shooting_tables = {table_elmt.get('id'): table_elmt for table_elmt in html_soup.find_all('table') if table_elmt.get('id')}\n",
    "    for table_id, table_elmt in shooting_tables.items():\n",
    "        if away in table_id:\n",
    "            team_type = 'away'\n",
    "            table_id = re.sub(away,team_type,table_id)\n",
    "            team = away\n",
    "            team_href = away_href\n",
    "        elif home in table_id:\n",
    "            team_type = 'home'\n",
    "            table_id = re.sub(home,team_type,table_id)\n",
    "            team = home\n",
    "            team_href = home_href\n",
    "        shooting_table_team = parse_html_table(str(table_elmt))\n",
    "        shooting_table_team.insert(0,'team',team)\n",
    "        shooting_table_team.insert(1,'team_href',team_href)\n",
    "        parsed_shot_charts[table_id] = shooting_table_team\n",
    "    return parsed_shot_charts\n",
    "\n",
    "\n",
    "def __parse_shotchart_tables_type2__(html_text):\n",
    "    html_soup = make_soup(html_text)\n",
    "    table_away_home_teams = __parse_game_info_tables__(html_text)['info-away-home-teams']\n",
    "    away,home = table_away_home_teams['team_id']\n",
    "    away_href,home_href = table_away_home_teams['team_href']\n",
    "\n",
    "    parsed_shot_charts = {}\n",
    "    shot_area_divs = {div_elmt.get('id'): div_elmt for div_elmt in html_soup.find_all('div', {'class': 'shot-area'}) if div_elmt.get('id')} \n",
    "    for div_id, div_elmt in shot_area_divs.items():\n",
    "        if away in div_id:\n",
    "            team_type = 'away'\n",
    "            div_id = re.sub(away,team_type,div_id)\n",
    "            team = away\n",
    "            team_href = away_href\n",
    "        elif home in div_id:\n",
    "            team_type = 'home'\n",
    "            div_id = re.sub(home,team_type,div_id)\n",
    "            team = home\n",
    "            team_href = home_href\n",
    "        tooltip_divs = div_elmt.find_all('div', {'class': 'tooltip'})\n",
    "\n",
    "        data = []\n",
    "        for tooltip_div in tooltip_divs:\n",
    "            classes_str = tooltip_div['class']\n",
    "            # parse quarter, player, shot result\n",
    "            _, q_class, player_code, shot_result = classes_str\n",
    "            quarter = int(re.search(r'q-(\\d)', q_class).group(1))\n",
    "            # parse shot position\n",
    "            style_str = tooltip_div['style']\n",
    "            px_match = re.search(r'top:(\\d+)px;left:(\\d+)px;', style_str)\n",
    "            px_y = int(px_match.group(1))\n",
    "            px_x = int(px_match.group(2))\n",
    "            # parse detailed info from description\n",
    "            tip_str = tooltip_div['tip']\n",
    "            description = re.sub('<br>',', ',tip_str)\n",
    "            time_str = re.findall(r'(\\d{1,2}:\\d{2}.\\d{1}) remaining', tip_str)[0]  # extract time\n",
    "            shot_distance = re.findall(r'from (\\d+?) ft', tip_str)[0] \n",
    "            score_str = re.findall(r'(\\d+-\\d+)', tip_str)[0]  # extract score\n",
    "            team_str = re.findall(r'<br>(\\w+|\\w+[\\s\\w+]+?) (?:now|tied|leads|trails)', tip_str)[0] \n",
    "            score_res_str = re.findall(r'(tied|leads|trails|now leads|now tied)', tip_str)[0] \n",
    "            data.append({\n",
    "                'quarter': quarter,\n",
    "                'time': time_str,\n",
    "                'player_code': player_code,\n",
    "                'shot_result': shot_result,\n",
    "                'distance': shot_distance,\n",
    "                'pos_x': px_x,\n",
    "                'pos_y': px_y,\n",
    "                'team': team_str,\n",
    "                'score_res': score_res_str,\n",
    "                'score': score_str,\n",
    "                'description': description,\n",
    "            })\n",
    "\n",
    "        parsed_shot_charts[f'shots-{team_type}'] = pd.DataFrame(data)\n",
    "\n",
    "    return parsed_shot_charts\n",
    "\n",
    "def parse_all_shotchart_tables(html_text):\n",
    "    parsed_shot_charts = {\n",
    "        **__parse_game_info_tables__(html_text),\n",
    "        **__parse_shotchart_tables_type1__(html_text),\n",
    "        **__parse_shotchart_tables_type2__(html_text)\n",
    "    }\n",
    "    return parsed_shot_charts\n",
    "\n",
    "href = 'https:/www.basketball-reference.com/boxscores/shot-chart/202211090OKC.html'\n",
    "url = f'{href}'\n",
    "html_text = fetch_html(url,source=base.LOCAL_HOST)\n",
    "html_soup = make_soup(html_text)\n",
    "\n",
    "parsed_shot_charts = parse_all_shotchart_tables(html_text)\n",
    "# iter_tables(parsed_shot_charts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __parse_plusminus_tables_type1__(html_text):\n",
    "    html_soup = make_soup(html_text)\n",
    "    plusminus_elmt = html_soup.find('div',{'class':'plusminus'}) \n",
    "    header_div = plusminus_elmt.find('div', class_='header')\n",
    "    headers = [h.text for h in header_div.find_all('div')]\n",
    "    df_header = pd.DataFrame({'quarter': headers, 'width': [int(d['style'].split(':')[-1].replace('px;', '')) for d in header_div.find_all('div')]})\n",
    "    return {'info-quarter-width': df_header}\n",
    "\n",
    "def __parse_plusminus_tables_type2__(html_text):\n",
    "    html_soup = make_soup(html_text)\n",
    "    table_away_home_teams = __parse_game_info_tables__(html_text)['info-away-home-teams']\n",
    "    away_name,home_name = table_away_home_teams['team_name']\n",
    "\n",
    "    table_type = 'plusminus-player-total'\n",
    "    plusminus_elmt = html_soup.find('div',{'class':'plusminus'})\n",
    "    parsed_pm_tables = {}\n",
    "    for team_pm_elmt in plusminus_elmt.div.find_all('div',recursive=False):\n",
    "        team_name = team_pm_elmt.find('h3').text\n",
    "        if away_name in team_name:\n",
    "            team_type = 'away'\n",
    "            table_name = f'{team_type}-{table_type}'\n",
    "        elif home_name in team_name:\n",
    "            team_type = 'home'\n",
    "            table_name = f'{team_type}-{table_type}'\n",
    "\n",
    "        team_player_divs = team_pm_elmt.find_all('div', recursive=False, class_='player')\n",
    "        team_player_pm = []\n",
    "        for player_div in team_player_divs:\n",
    "            player_name = player_div.find('span').text\n",
    "            player_on = re.findall(r\"On: ([-+]*\\d+)\", player_div.text)[0]\n",
    "            player_off = re.findall(r\"Off: ([-+]*\\d+)\", player_div.text)[0]\n",
    "            player_net = re.findall(r\"Net: ([-+]*\\d+)\", player_div.text)[0]\n",
    "            player_dict = {\n",
    "                'team_name': team_name,\n",
    "                'player_name': player_name,\n",
    "                'player_on': player_on,\n",
    "                'player_off': player_off,\n",
    "                'player_net': player_net,\n",
    "            }\n",
    "            team_player_pm.append(player_dict)\n",
    "        df_team_pm = pd.DataFrame(team_player_pm)\n",
    "        parsed_pm_tables[table_name] = df_team_pm\n",
    "    return parsed_pm_tables\n",
    "\n",
    "def __parse_plusminus_tables_type3__(html_text):\n",
    "    html_soup = make_soup(html_text)\n",
    "    table_away_home_teams = __parse_game_info_tables__(html_text)['info-away-home-teams']\n",
    "    away_name,home_name = table_away_home_teams['team_name']\n",
    "\n",
    "    table_type = 'player-plusminus-on-off'\n",
    "    plusminus_elmt = html_soup.find('div',{'class':'plusminus'})\n",
    "    parsed_pm_tables = {}\n",
    "    for team_pm_elmt in plusminus_elmt.div.find_all('div',recursive=False):\n",
    "        team_name = team_pm_elmt.find('h3').text\n",
    "        if away_name in team_name:\n",
    "            team_type = 'away'\n",
    "            table_name = f'{team_type}-{table_type}'\n",
    "        elif home_name in team_name:\n",
    "            team_type = 'home'\n",
    "            table_name = f'{team_type}-{table_type}'\n",
    "\n",
    "        player_divs = team_pm_elmt.find_all('div', {'class':'player'}, recursive=False)\n",
    "        player_pm_divs = team_pm_elmt.find_all('div', {'class':'player-plusminus'}, recursive=False, )\n",
    "        team_pm_list = []\n",
    "        for player_div, player_pm_div in zip(player_divs,player_pm_divs):\n",
    "            player_name = player_div.find('span').text\n",
    "            player_pm_list = []\n",
    "            for pm_div in player_pm_div.find_all('div'):\n",
    "                pm_class = pm_div.get('class')[0] if pm_div.get('class') is not None else 'off'\n",
    "                pm_width = int(pm_div['style'].split(':')[-1].replace('px;', ''))\n",
    "                pm_value = pm_div.text if pm_div.text.strip() != '' else '0'\n",
    "                player_pm_list.append({\n",
    "                    'team_name': team_name,\n",
    "                    'player_name' : player_name,\n",
    "                    'pm_class': pm_class,\n",
    "                    'pm_width': pm_width,\n",
    "                    'pm_value': pm_value,\n",
    "                })\n",
    "            player_pm_list = pd.DataFrame(player_pm_list)\n",
    "            team_pm_list.append(player_pm_list)\n",
    "        df_team_plusminus = pd.concat(team_pm_list).reset_index()\n",
    "        parsed_pm_tables[table_name] = df_team_plusminus\n",
    "    return parsed_pm_tables\n",
    "\n",
    "def parse_all_plusminus_tables(html_text):\n",
    "    parsed_plusminus_charts = {\n",
    "        **__parse_game_info_tables__(html_text),\n",
    "        **__parse_plusminus_tables_type1__(html_text),\n",
    "        **__parse_plusminus_tables_type2__(html_text),\n",
    "        **__parse_plusminus_tables_type3__(html_text),\n",
    "    }\n",
    "    return parsed_plusminus_charts\n",
    "\n",
    "href = 'https:/www.basketball-reference.com/boxscores/plus-minus/201812220WAS.html'\n",
    "url = f'{href}'\n",
    "html_text = fetch_html(url,source=base.LOCAL_HOST)\n",
    "html_soup = make_soup(html_text)\n",
    "\n",
    "parsed_pm_tables = parse_all_plusminus_tables(html_text)\n",
    "# iter_tables(parsed_pm_tables,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p/pettibo01'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_id(text,query):\n",
    "    patterns = {\n",
    "        'boxscore'   : r'/(\\d+\\w{3})',\n",
    "        'team'       : r'(\\b[A-Z]{3}\\b)',\n",
    "        'team/season': r'(\\b[A-Z]{3}/\\d{4})',\n",
    "        'season'     : r'(\\b\\d{4})',\n",
    "        'player'     : r'(\\b\\w/\\w+\\d{2}\\b)'\n",
    "    }\n",
    "    try: \n",
    "        return re.search(patterns[query], text).group(1)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "href = 'https:/www.basketball-reference.com/boxscores/201812220WAS.html'\n",
    "href = 'https://www.basketball-reference.com/teams/ATL/'\n",
    "href = 'https://www.basketball-reference.com/teams/ATL/2021.html'\n",
    "href = 'https://www.basketball-reference.com/players/p/pettibo01.html'\n",
    "extract_id(href, 'player')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "home-player-plusminus-on-off: 100%|██████████| 58/58 [01:56<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "def parse_boxscores(href,boxscore_query = ['boxscores','pbp','shot-chart','plus-minus'],from_local=base.LOCAL_HOST):\n",
    "    parsed_boxscores_tables = {}\n",
    "    parsed_pbp_tables = {}\n",
    "    parsed_shotchart_tables = {}\n",
    "    parsed_pm_tables = {}\n",
    "\n",
    "    boxscore_id =  extract_id(href,query='boxscore')\n",
    "    for query in to_list(boxscore_query):\n",
    "        if query in ['boxscores','boxscore',None]:\n",
    "            bxscr_href = f'https://www.basketball-reference.com/boxscores/{boxscore_id}.html'\n",
    "            html_text = fetch_html(bxscr_href,source=from_local)\n",
    "            parsed_boxscores_tables = parse_all_boxscores_tables(html_text)\n",
    "\n",
    "        elif query in ['play-by-play','pbp']:\n",
    "            bxscr_href = f'https://www.basketball-reference.com/boxscores/pbp/{boxscore_id}.html'\n",
    "            html_text = fetch_html(bxscr_href,source=from_local)\n",
    "            parsed_pbp_tables = parse_all_pbp_tables(html_text)\n",
    "\n",
    "        elif query in ['shot-chart','shotchart']:\n",
    "            bxscr_href = f'https://www.basketball-reference.com/boxscores/shot-chart/{boxscore_id}.html'\n",
    "            html_text = fetch_html(bxscr_href,source=from_local)\n",
    "            parsed_shotchart_tables = parse_all_shotchart_tables(html_text)\n",
    "\n",
    "        elif query in [ 'plus-minus','plusminus']:\n",
    "            bxscr_href = f'https://www.basketball-reference.com/boxscores/plus-minus/{boxscore_id}.html'\n",
    "            html_text = fetch_html(bxscr_href,source=from_local)\n",
    "            parsed_pm_tables = parse_all_plusminus_tables(html_text)\n",
    "\n",
    "    parsed_boxscores = {\n",
    "        **parsed_boxscores_tables,\n",
    "        **parsed_pbp_tables,\n",
    "        **parsed_shotchart_tables,\n",
    "        **parsed_pm_tables,        \n",
    "    }\n",
    "    return parsed_boxscores\n",
    "\n",
    "href = 'https:/www.basketball-reference.com/boxscores/201812220WAS.html'\n",
    "parsed_boxscores = parse_boxscores(href,from_local=base.LOCAL_HOST)\n",
    "iter_tables(parsed_boxscores,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Example Usage:\n",
      "    -------\n",
      "    ```\n",
      "    checkpoint = Checkpoint(levels=3)\n",
      "    for i in range(10):\n",
      "        if checkpoint.skip_this_point(i):\n",
      "            # Skip points prior to checkpoint\n",
      "            continue\n",
      "        for j in range(10):\n",
      "            if checkpoint.skip_this_point(i,j):\n",
      "                # Skip points prior to checkpoint\n",
      "                continue\n",
      "            for k in range(10):\n",
      "                if checkpoint.skip_this_point(i,j,k):\n",
      "                    # Skip points prior to checkpoint\n",
      "                    continue\n",
      "                # Only executes when the checkpoint is reached\n",
      "                # Do something\n",
      "                print(i,j,k)\n",
      "                time.sleep(0.5)\n",
      "                # Update and save\n",
      "                checkpoint.update(i,j,k)\n",
      "                checkpoint.save()\n",
      "    # Delete when task is finished\n",
      "    checkpoint.delete()\n",
      "    ```\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "checkpoint = Checkpoint(levels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7 ms ± 60.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "1.01 ms ± 22.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# df = parsed_pbp_tables['pbp']\n",
    "# %timeit df.to_csv('test.csv')\n",
    "# %timeit df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 -rw-r--r--  1 jasetran  staff    55K Apr 24 19:09 test.csv\n"
     ]
    }
   ],
   "source": [
    "# !ls -GFlash test.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
